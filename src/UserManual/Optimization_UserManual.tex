% Copyright (c)  2005-2010 EDF-EADS-PHIMECA.
% Permission is granted to copy, distribute and/or modify this document
% under the terms of the GNU Free Documentation License, Version 1.2
% or any later version published by the Free Software Foundation;
% with no Invariant Sections, no Front-Cover Texts, and no Back-Cover
% Texts.  A copy of the license is included in the section entitled "GNU
% Free Documentation License".
\newpage\section{Optimization}

\subsection{Minimization of the distance under an equality constraint}

\subsubsection{NearestPointAlgorithm}

\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $NearestPointAlgorithm(levelFunction)$
  \item $NearestPointAlgorithm(nearestPointAlgorithmImplementation)$
  \end{description}

\item[Arguments :] \rule{0pt}{1em}
  \begin{description}
  \item $levelFunction$ : a NumericalMathFunction, the constraint function of the constrained optimization problem.
  \item $nearestPointAlgorithmImplementation$ : a NearestPointAlgorithmImplementation, the implementation of the nearest point algorithm, which is $Cobyla$ , $AbdoRackwitz$ or $SQP$.
  \end{description}

\item[Details :] a NearestPointAlgorithm, which resolves the optimization problem :
  $$
  \min_{f(\vect{u}) = 0} ||\vect{U}||^2
  $$
  where $f$ is the $levelFunction$.
  \begin{description}
  \item in the first usage, the optimization algorithm is the Cobyla one with its default specific parameters.
  \item in the second usage, the optimization algorithm is specified by the $nearestPointAlgorithmImplementation$.
  \end{description}

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getLevelFunction$
    \begin{description}
    \item[Usage :] $getLevelFunction()$
    \item[Arguments :] none
    \item[Value :]  a NumericalMathFunction, the constraint function of the constrained optimization problem
    \end{description}
    \bigskip

  \item $getLevelValue$
    \begin{description}
    \item[Usage :] $getLevelFunction()$
    \item[Arguments :] none
    \item[Value :]  a real value, the level value of the constraint function in the constrained optimization problem
    \end{description}
    \bigskip

  \item $getMaximumAbsoluteError$
    \begin{description}
    \item[Usage :] $getMaximumAbsoluteError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the maximum absolute error : maximum distance between two successive iterates
    \end{description}
    \bigskip

  \item $getMaximumConstraintError$
    \begin{description}
    \item[Usage :] $getMaximumConstraintError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the maximum absolute value of the constraint function minus the level value
    \end{description}
    \bigskip

  \item $getMaximumIterationsNumber$
    \begin{description}
    \item[Usage :] $getMaximumIterationsNumber()$
    \item[Arguments :] none
    \item[Value :] an integer, the maximum number of iterations of the algorithm
    \end{description}
    \bigskip

  \item $getMaximumRelativeError$
    \begin{description}
    \item[Usage :] $geMaximumtRelativeError()$
    \item[Arguments :] none
    \item[Value :] a real value, the maximum relative distance between two successive iterates (with regards the second iterate)
    \end{description}
    \bigskip

  \item $getMaximumResidualError$
    \begin{description}
    \item[Usage :] $getMaximumResidualError()$
    \item[Arguments :] none
    \item[Value :] a real value, the maximum orthogonality error (lack of orthogonality between the vector Center - Iterate and the constraint surface)
    \end{description}
    \bigskip

  \item $getResult$
    \begin{description}
    \item[Usage :] $getResult()$
    \item[Arguments :] none
    \item[Value :] a NearestPointAlgorithmImplementationResult, the structure containing all the results of the constrained optimization problem
    \end{description}
    \bigskip

  \item $getStartingPoint$
    \begin{description}
    \item[Usage :] $getStartingPoint()$
    \item[Arguments :] none
    \item[Value :] a NumericalPoint, the starting point of the constrained optimization research
    \end{description}
    \bigskip

  \item $run$
    \begin{description}
    \item[Usage :] $run()$
    \item[Arguments :] none
    \item[Value :] none
    \item[Role :] it creates a NearestPointAlgorithmImplementationResult, the optimization result which is accessible with the method getResult().
    \end{description}
  \end{description}

  Each  $getMethod$  is associated to a $setMethod$.


\end{description}

% =============================================================
\newpage \subsubsection{Cobyla}

This class inherits from the NearestPointAlgorithmImplementation class.
\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $Cobyla()$
  \item $Cobyla(specificParameters,  levelFunction)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $specificParameters$ : a CobylaSpecificParameters, the list of the parameters specific to the Cobyla algorithm
  \item $levelFunction$ : a NumericalMathFunction, the constraint function of the constrained optimization problem
  \end{description}

\item[Details :]  When no argument is specified, the parameters will have to be fulfilled after, for example, when used in a FORM algorithm (see the corresponding Use Case).

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getSpecificParameters$
    \begin{description}
    \item[Usage :] $getSpecificParameters()$
    \item[Arguments :] none
    \item[Value :]  a CobylaSpecificParameters, the list of the parameters specific to the Cobyla algorithm
    \end{description}
    \bigskip
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.

\end{description}

% =============================================================
\newpage \subsubsection{CobylaSpecificParameters}


\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $CobylaSpecificParameters()$
  \item $CobylaSpecificParameters(rhoBeg)$
  \end{description}

\item[Arguments :]  $rhoBeg$ :  a real positive strictly value, a reasonable initial step to the variables.

\item[Values :]  \rule{0pt}{1em}

  \begin{description}
  \item in the first usage, the default values are considered for each parameter : $rhoBeg = 0.1$.
  \item  in the second usage, the parameter $rhoBeg$ is specified.
  \end{description}




\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getRhoBeg$
    \begin{description}
    \item[Usage :] $getRhoBeg()$
    \item[Arguments :] none
    \item[Value :]  a real value >0, a reasonable initial step to the variables
    \end{description}
    \bigskip
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.
\end{description}
% =============================================================
\newpage \subsubsection{AbdoRackwitz}

This class inherits from the NearestPointAlgorithmImplementation class.

\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $AbdoRackwitz()$
  \item $AbdoRackwitz(specificParameters,  levelFunction)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $specificParameters$ : a AbdoRackwitzSpecificParameters, the list of the parameters specific to the AbdoRackwitz algorithm
  \item $levelFunction$ : a NumericalMathFunction, the constraint function of the constrained optimization problem
  \end{description}

\item[Details :]  When no argument is specified, the parameters will have to be fulfilled after, for example, when used in a FORM algorithm (see the corresponding Use Case).

  The AbdoRackwitz algorithm is a gradient-based constrained optimization method, thus the NumericalMathFunction has to provide its gradient:
  \begin{itemize}
  \item If the function is a meta-model generated by OpenTURNS, the analytical gradient is automatically provided.
  \item If it is an analytical function, OpenTURNS provides a gradient based on the centered finite difference method, that the user can change to better fit ots will by another GradientImplementation (e.g. constructed by another finite difference method).
  \item If the function is loaded thanks to a wrapper and if the wrapper provide an implementation of the gradient, OpenTURNS uses it. If there is no gradient provided, OpenTURNS provides a gradient based on centered finite difference method, but with a parameterization different from the case of analytical functions (assuming a lower precision for the function evaluation than in the analytical case).
  \end{itemize}
  Be aware of the potential pitfalls associated with the use of finite differences and check the value of the finite difference epsilon for each dimension if AbdoRackwitz algorithm fails to converge.

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getSpecificParameters$
    \begin{description}
    \item[Usage :] $getSpecificParameters()$
    \item[Arguments :] none
    \item[Value :]  a AbdoRackwitzSpecificParameters, list of the parameters specific to the AbdoRackwitz algorithm
    \end{description}
    \bigskip
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.
\end{description}

% =============================================================
\newpage \subsubsection{AbdoRackwitzSpecificParameters}


\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $AbdoRackwitzSpecificParameters()$
  \item $AbdoRackwitzSpecificParameters(Tau, Omega, Smooth)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $Tau$ :  a real positive value, the multiplicative decrease of the linear step. It  must be $<1$.
  \item $Omega$ :  a real strictly positive value, the Armijo factor. It  must be $<1$ and should be rather small.
  \item $Smooth$ :  a real value $>1$, the increasing rate of the penalisation coefficient for the line search. It  must be $>1$ and should be rather near 1.
  \end{description}

\item[Values :]  \rule{0pt}{1em}

  \begin{description}
  \item in the first usage, the default values are considered for each parameter : $Tau = 0.5$, $Omega = 10^{-4}$, $Smooth = 1.2$.
  \item  in the second usage, all the parameters are specified.
  \end{description}


\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getOmega$
    \begin{description}
    \item[Usage :] $getOmega()$
    \item[Arguments :] none
    \item[Value :]  a real value between 0 and 1, the Armijo factor
    \end{description}
    \bigskip

  \item $getSmooth$
    \begin{description}
    \item[Usage :] $getSmooth()$
    \item[Arguments :] none
    \item[Value :]  a real value $> 1$, the increasing rate of the penalisation coefficient for the line search
    \end{description}
    \bigskip

  \item $getTau$
    \begin{description}
    \item[Usage :] $getTau()$
    \item[Arguments :] none
    \item[Value :]  a real value between 0 and 1, the multiplicative decrease of the linear step
    \end{description}
    \bigskip
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.
\end{description}

% =============================================================
\newpage \subsubsection{SQP}

This class inherits from the NearestPointAlgorithmImplementation class.
\begin{description}
\item[Usage :] $SQP(specificParameters, levelFunction)$

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $specificParameters$ : a SQPSpecificParameters, list of the parameters specific to the SQP algorithm
  \item $levelFunction$ : a NumericalMathFunction, the constraint function of the constrained optimization problem
  \end{description}
\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getSpecificParameters$
    \begin{description}
    \item[Usage :] $getSpecificParameters()$
    \item[Arguments :] none
    \item[Value :]  a SQPSpecificParameters, list of the parameters specific to the SQP algorithm
    \end{description}
    \bigskip
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.
\end{description}

% =============================================================
\newpage \subsubsection{SQPSpecificParameters}


\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $SQPSpecificParameters()$
  \item $SQPSpecificParameters(Omega, Smooth, Tau)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $Omega$ :  a real value, the Armijo factor, must be > 0 and <1 but rather small.
  \item $Smooth$ :  a real value, the increasing rate of the penalisation coefficient for the line search, must be >1 but rather near 1.
  \item $Tau$ :  a real value, the multiplicative decrease of the linear step, must be > 0 and <1.

  \end{description}

\item[Values :]  \rule{0pt}{1em}

  \begin{description}
  \item in the first usage, the default values are considered for each parameter : $Omega = 10^{-4}$, $Smooth = 1.2$, $Tau = 0.5$.
  \item  in the second usage, all the parameters are specified.
  \end{description}


\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getOmega$
    \begin{description}
    \item[Usage :] $getOmega()$
    \item[Arguments :] none
    \item[Value :]  a real value between 0 and 1, Armijo factor
    \end{description}
    \bigskip

  \item $getSmooth$
    \begin{description}
    \item[Usage :] $getSmooth()$
    \item[Arguments :] none
    \item[Value :]  a real value > 1, the increasing rate of the penalisation coefficient for the line search
    \end{description}
    \bigskip

  \item $getTau$
    \begin{description}
    \item[Usage :] $getTau()$
    \item[Arguments :] none
    \item[Value :]  a real value between 0 and 1, multiplicative decrease of the linear step
    \end{description}
    \bigskip
  \end{description}

  These  $getMethod$  are associated to  $setMethod$.
\end{description}

% =============================================================
\newpage \subsubsection{NearestPointAlgorithmImplementationResult}


\begin{description}
\item[Usage :] structure created by the method run() of a NearestPointAlgorithm and obtained thanks to the method $getResult()$

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getAbsoluteError$
    \begin{description}
    \item[Usage :] $getAbsoluteError()$
    \item[Arguments :] none
    \item[Value :]  a NumericalScalar, the absolute error : the distance between the two last successive iterates when the algorithm stops
    \end{description}
    \bigskip

  \item $getConstraintError$
    \begin{description}
    \item[Usage :] $getConstraintError()$
    \item[Arguments :] none
    \item[Value :] a real value, the absolute value of the constraint function minus the level value at the last iterate point when the algorithm stops
    \end{description}
    \bigskip

  \item $getIterationsNumber$
    \begin{description}
    \item[Usage :] $getIterationsNumber()$
    \item[Arguments :] none
    \item[Value :]  an integer, the  number of performed iterations of the algorithm when the algorithm stops
    \end{description}
    \bigskip

  \item $getMinimizer$
    \begin{description}
    \item[Usage :] $getMinimizer()$
    \item[Arguments :] none
    \item[Value :]  a NumericalPoint, the last iterate when the algorithm stops (the solution of the optimization problem)
    \end{description}
    \bigskip

  \item $getRelativeError$
    \begin{description}
    \item[Usage :] $getRelativeError()$
    \item[Arguments :] none
    \item[Value :] a real value, the relative distance between the two last successive iterates (with regards the last iterate)
    \end{description}
    \bigskip

  \item $getResidualError$
    \begin{description}
    \item[Usage :] $getResidualError()$
    \item[Arguments :] none
    \item[Value :]   a real value, the orthogonality error of the solution point (lack of orthogonality between the vector Center - Last Iterate and the constraint surface)
    \end{description}

  \end{description}

\end{description}


% =============================================================

\newpage  \subsection{Optimization of a function under an inequality constraint}

\subsubsection{BoundConstrainedAlgorithm}

\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $BoundConstrainedAlgorithm(objFct, boundCons, startingPt, ...$\\
$ ... BndConstAlgoImp.MINIMIZATION)$
  \item $BoundConstrainedAlgorithm(objFct, boundCons, startingPt, ...$\\
$ ... BndConstAlgoImp.MAXIMIZATION)$
  \item $BoundConstrainedAlgorithm(BndConstAlgoImp)$
  \end{description}

\item[Arguments :] \rule{0pt}{1em}
  \begin{description}
  \item $objFct$ : a NumericalMathFunction, the function to minimize or maximize (objective function).
  \item $startingPt$ : a Interval, the intervall $[\vect{a}, \vect{b}] \in \overline{\mathbb{R}}^n$.
  \item $startingPt$ : a NumericalPoint, the initial point of the optimization algorithm.
  \item $BndConstAlgoImp.MINIMIZATION$ : the code which specifies that it is a minimization optimization. It is possible to write $O$ instead of it.
  \item $BndConstAlgoImp.MAXIMIZATION$ : the code which specifies that it is a maximization optimization. It is possible to write $1$ instead of it.
  \item $boundConstrainAlgorithmImplementation$ : a BoundConstrainAlgorithmImplementation, the implementation of the bound constrain algorithm, which is $TNC$.
  \end{description}

\item[Value :] a BoundConstrainedAlgorithm, which resolves the optimization problems :
  $$
  \min_{\vect{a} \leq \vect{u} \leq \vect{b} } f(\vect{u})
  $$
  or
  $$
  \max_{\vect{a} \leq \vect{u} \leq \vect{b} } f(\vect{u})
  $$
  where $f$ is the objective function and $[\vect{a},\vect{b}] \in \overline{\mathbb{R}}^n$.
  \begin{description}
  \item In the first and second usages, the optimization algorithm is the TNC one with its default specific parameters.
  \item In the third usage, the optimization problem is entirely specified by the implementation of the bound constrain algorithm.
  \end{description}

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getBoundConstraints$
    \begin{description}
    \item[Usage :] $getBoundConstraints()$
    \item[Arguments :] none
    \item[Value :]  a Interval, the interval $[\vect{a},\vect{b}] \in \overline{\mathbb{R}}^n$ where the optimization is performed.
    \end{description}
    \bigskip

  \item $getMaximumAbsoluteError$
    \begin{description}
    \item[Usage :] $getMaximumAbsoluteError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, precision goal for the value of x in the stopping criterion (after applying x scaling factors). If negative 0.0, that parameter is set to $\sqrt{machine-precision}$.
    \end{description}
    \bigskip

  \item $getMaximumConstraintError$
    \begin{description}
    \item[Usage :] $getMaximumConstraintError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the precision goal for the value of the projected gradient in the stopping criterion (after applying x scaling factors) : if negative, that parameter is set to 1e-2 * sqrt(accuracy). Setting it to 0.0 is not recommended.
    \end{description}
    \bigskip

  \item $getMaximumEvaluationsNumber$
    \begin{description}
    \item[Usage :] $getMaximumEvaluationsNumber()$
    \item[Arguments :] none
    \item[Value :] an integer, the maximum number of evaluations of the objective function.
    \end{description}
    \bigskip

  \item $getMaximumObjectiveError$
    \begin{description}
    \item[Usage :] $getMaximumObjectiveError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the precision goal for the value of the objevive function in the stoping criterion. If negative, that parameter is set to accuracy.
    \end{description}
    \bigskip

  \item $getObjectiveFunction$
    \begin{description}
    \item[Usage :] $getObjectiveFunction()$
    \item[Arguments :] none
    \item[Value :] a NumericalMathFunction, the objective function.
    \end{description}
    \bigskip

  \item $getResult$
    \begin{description}
    \item[Usage :] $getResult()$
    \item[Arguments :] none
    \item[Value :] a BoundConstrainedAlgorithmImplementationResult, the structure containing all the results of the constrained optimization problem
    \end{description}
    \bigskip

  \item $getStartingPoint$
    \begin{description}
    \item[Usage :] $getStartingPoint()$
    \item[Arguments :] none
    \item[Value :] a NumericalPoint, the starting point of the constrained optimization research.
    \end{description}
    \bigskip

  \item $run$
    \begin{description}
    \item[Usage :] $run()$
    \item[Arguments :] none
    \item[Value :] none
    \item[Role :] it creates a BoundConstrainedAlgorithmImplementationResult, the optimization result which is accessible with the method getResult().
    \end{description}


  \end{description}


  These  $getMethod$  are associated to  $setMethod$.


\end{description}



% =============================================================


\newpage                 \subsubsection{TNC (Truncated Newton Constrained)}

This class inherits from the BoundConstrainedAlgorithmImplementation class.\\

The TNC algorithm minimizes or maximizes an objective function $f$ with variables $x$ subjected to bounds $[\vect{a},\vect{b}] \in \overline{\mathbb{R}}^n$ , using gradient information.

\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $TNC(specParam,  objFct, boundCons, startPt, TNC.MINIMIZATION)$
  \item $TNC(specParam,  objFct, boundCons, startPt, TNC.MAXIMIZATION)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $specParam$ : a TNCSpecificParameters, the list of the parameters specific to the TNC algorithm
  \item $objFct$ : a NumericalMathFunction, the constraint function of the constrained  problem
  \item $boundCons$ : a Interval, the interval $[\vect{a},\vect{b}] \in \overline{\mathbb{R}}^n$ where the optimization is performed.
  \item $startingPoint$ : a NumericalPoint, the starting point of the constrained optimization research.
  \item $TNC.MINIMIZATION, TNC.MAXIMIZATION$  :  the code which specifies whether it is a minimization or a maximization optimization. It is possible to write $0$ instead of $TNC.MINIMIZATION$ and $1$ instead of $TNC.MAXIMIZATION$.
  \end{description}

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getSpecificParameters$
    \begin{description}
    \item[Usage :] $getSpecificParameters()$
    \item[Arguments :] none
    \item[Value :]  a TNCSpecificParameters, the list of the parameters specific to the TNC algorithm
    \end{description}
  \end{description}

  This  $getMethod$  is associated to a $setMethod$.

\end{description}



% =============================================================


\newpage                 \subsubsection{TNCSpecificParameters}

The TNC algorithm resolves : $\min_{\vect{x} \in [\vect{a},\vect{b}] \in \overline{\mathbb{R}}^n} f(\vect{x})$ and proceeds as follows under the proper regularity of the objective function $f$ :
$$
\left\{
  \begin{array}{l}
    \vect{\nabla f}(\vect{x}) =\vect{0}  \\
    \mat{\nabla_2} f(\vect{x}) \mbox{ is definite positive}
  \end{array}
\right.
$$

The Taylor development of second order of $f$ around  $\vect{x}_k$ leads to the determination of the iterate $\vect{x}_{k+1}$ such as :
\begin{equation}\label{linearSystem}
  \left\{
    \begin{array}{lcl}
      \vect{\Delta}_k & = & \vect{x}_{k+1} - \vect{x}_k  \\
      \mat{\nabla_2} f(\vect{x}_k)\vect{\Delta}_k & = & -\vect{\nabla f}(\vect{x}_k)
    \end{array}
  \right.
\end{equation}

The equation (\ref{linearSystem}) is truncated : the iterative research of $\vect{\Delta}_k$ is stopped as soon as $\vect{\Delta}_k$ verifies :
$$
|| \mat{\nabla_2} f(\vect{x}_k)\vect{\Delta}_k + \vect{\nabla f}(\vect{x}_k) || \leq \eta ||\vect{\nabla f}(\vect{x}_k) ||
$$
At last, the iteration $k+1$ is defined by :
$$
\vect{x}_{k+1} = \vect{x}_k + \alpha_k \vect{\Delta}_k
$$
where $\alpha_k$ is the parameter $stepmx$.



\begin{description}
\item[Usage :] \rule{0pt}{1em}
  \begin{description}
  \item $TNCSpecificParameters()$
  \item $TNCSpecificParameters(scale, offset, maxCGit, eta, stepmx, ...$\\
$ ... accuracy, fmin, rescale)$
  \end{description}

\item[Arguments :]  \rule{0pt}{1em}
  \begin{description}
  \item $scale$ :  a real value, the scaling factors to apply to each variable : if NULL, the factors are up-low for interval bounded variables and 1+|x] for the others.
  \item $offset$ : a real value, the constant to substract to each variable. If NULL, the constant are (up+low)/2 for interval bounded variables and x for the others.
  \item $maxCGit$ : an integer, the max. number of hessian*vector evaluation per main iteration. If maxCGit == 0, the direction chosen is -gradient. If maxCGit < 0, maxCGit is set to max(1,min(50,n/2)).
  \item $eta$ :  a positive real value, the severity of the line search. If < 0 or > 1, set to 0.25.
  \item $stepmx$ :   a real value, the maximum step for the line search. may be increased during call. If too small, will be set to 10.0.
  \item $accuracy$ :  a real value, the relative precision for finite difference calculations. If $\leq machine-precision$, set to $\sqrt{machine-precision}$.
  \item $fmin$ :   a real value, the minimum function value estimate
  \item $rescale$ : a real value, the objective function scaling factor (in log10) used to trigger the objective function value rescaling : if 0, rescale at each iteration; if a big value, never rescale; if < 0, rescale is set to 1.3.
  \end{description}


\item[Value :]  \rule{0pt}{1em}

  \begin{description}
  \item in the first usage, the default values are considered for each parameter : $MaxCGit = 50$, $Eta = 0.25$, $Stepmx = 10.0$, $Accuracy = 1.0e-4$, $Fmin = 1.0$, $Rescale = 1.3$.
  \item  in the second usage, all the parameters are specified.
  \end{description}





\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getAccuracy$
    \begin{description}
    \item[Usage :] $getAccuracy()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $accuracy$ parameter.
    \end{description}
    \bigskip
  \item $getEta$
    \begin{description}
    \item[Usage :] $getEta()$
    \item[Arguments :] none
    \item[Value :]  a positive real value, the $eta$ parameter.
    \end{description}
    \bigskip
  \item $getFmin$
    \begin{description}
    \item[Usage :] $getFmin()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $fmin$ parameter.
    \end{description}
    \bigskip
  \item $getMaxCGit$
    \begin{description}
    \item[Usage :] $getMaxCGit()$
    \item[Arguments :] none
    \item[Value :]  an integer, the $maxCGit$ parameter.
    \end{description}
    \bigskip
  \item $getOffset$
    \begin{description}
    \item[Usage :] $getOffset()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $offset$ parameter.
    \end{description}
    \bigskip
  \item $getRescale$
    \begin{description}
    \item[Usage :] $getRescale()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $rescale$ parameter.
    \end{description}
    \bigskip
  \item $getScale$
    \begin{description}
    \item[Usage :] $getScale()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $scale$ parameter.
    \end{description}
    \bigskip
  \item $getStepmx$
    \begin{description}
    \item[Usage :] $getStepmx()$
    \item[Arguments :] none
    \item[Value :]  a real value, the $stepmx$ parameter.
    \end{description}
  \end{description}

  These  $getMethod$  are associated to  $setMethod$.
\end{description}


% =============================================================

\newpage                 \subsubsection{BoundConstrainedAlgorithmImplementationResult}



\begin{description}
\item[Usage :] structure created by the method run() of a BoundConstrainedAlgorithm and obtained thanks to the method $getResult()$

\item[Some methods :]  \rule{0pt}{1em}

  \begin{description}

  \item $getAbsoluteError$
    \begin{description}
    \item[Usage :] $getAbsoluteError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, precision obtained for the value of x in the stopping criterion (after applying x scaling factors). Care : if the algorithm is TNC, there is no information on that parameter : the Maximum absolute error is returned.
    \end{description}
    \bigskip

  \item $getConstraintError$
    \begin{description}
    \item[Usage :] $getConstraintError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the precision obtained for the value of the projected gradient in the stopping criterion (after applying x scaling factors).  Care : if the algorithm is TNC, there is no information on that parameter : the maximum constraint error is returned.
    \end{description}
    \bigskip

  \item $getEvaluationsNumber$
    \begin{description}
    \item[Usage :] $getEvaluationsNumber()$
    \item[Arguments :] none
    \item[Value :] an integer, the  number of evaluations of the objective function.
    \end{description}
    \bigskip

  \item $getObjectiveError$
    \begin{description}
    \item[Usage :] $getObjectiveError()$
    \item[Arguments :] none
    \item[Value :] a positive real value, the precision obtained for the value of the objevive function in the stoping criterion. Care : if the algorithm is TNC, there is no information on that parameter : the maximum objective error is returned.
    \end{description}
    \bigskip

  \item $getOptimalValue$
    \begin{description}
    \item[Usage :] $getOptimalValue()$
    \item[Arguments :] none
    \item[Value :] a real, the objective function value at the optimizer point.
    \end{description}
    \bigskip

  \item $getOptimmizer$
    \begin{description}
    \item[Usage :] $getOptimmizer()$
    \item[Arguments :] none
    \item[Value :] a NumericalPoint, solution of the constrained optimization problem.
    \end{description}


  \end{description}

\end{description}
